# --- Hetero-Latent-QMIX specific parameters ---
name: "hetero_qmix_latent"
runner: "hetero_episode"  # TODO
agent: "hetero_latent"
mac: "hetero_latent_mac"
learner: "hetero_latent_q_learner"
mixer: "hetero_qmix"  # TODO

# use epsilon greedy action selector
action_selector: "epsilon_greedy"
epsilon_start: 1.0
epsilon_finish: 0.05
#epsilon_anneal_time: 50
epsilon_anneal_time: 50000  # TODO: 1000000


#runner: "parallel"  # TODO
#batch_size_run: 8  # TODO
buffer_size: 5000

# update the target network every {} episodes
target_update_interval: 200

# use the Q_Learner to train
agent_output_type: "q"
double_q: True
mixing_embed_dim: 32

# for latent model
latent_dim: 16  # 3
latent_hidden_dim: 32  # 16
kl_loss_weight: 1  # TODO
kl_loss_threshold: 0.005  # TODO
h_loss_weight: 0.0001
var_floor: 0.002
dis_loss_weight: 0.001
dis_time: 0
soft_constraint_weight: 1.0
MI_Ablation: False
MI_Disable: False
input_latent: False  # TODO
latent_matmul: False  # TODO
relu_qmix: False  # TODO
adam_lr: 0.0003  # TODO: 1e-3 -- 1e-5
lr_episode_size: 50000  # TODO
lr_scheduler_gamma: 0.5  # TODO
universal_training: True  # TODO

use_tensorboard: True
save_model: True
#use_cuda: True  # False  # set in default.yaml
device_num: 0
save_replay: False

# --- Agent parameters ---
rnn_hidden_dim: 64 # Size of hidden state for default rnn agent
n_medivacs: 0  # number of medivacs
n_marauders: 0  # number of marauders

universal_qmix: False  # TODO
w_qmix: False  # TODO
hier_qmix: False  # TODO
n_agent_type: 2
vs_input: False  # TODO
hypernet_layers: 2
hypernet_embed: 64
t_alternate_training: 0  # 3000000

central_loss: 1
qmix_loss: 1
w: 0.1 # $\alpha$ in the paper
hysteretic_qmix: True # False -> CW-QMIX, True -> OW-QMIX

central_mixing_embed_dim: 256
central_action_embed: 1
central_mac: "central_basic_mac"
central_agent: "central_rnn"
central_rnn_hidden_dim: 64
central_mixer: "ff"

# for interpretability
verbose: False
